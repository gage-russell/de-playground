postgresql:
  # databases are created from templates/dbinit.yaml
  # default user/secret being used
  enabled: true
  primary:
    pgHbaConfiguration: |-
      host all all 0.0.0.0/0 trust

marquez:
  enabled: true

  marquez:
    db:
      user: postgres
      host: playground-postgresql.playground-ns.svc.cluster.local
      name: marquez
      existingSecret: playground-postgresql

    port: 80

    hostname: playground-marquez.playground-ns.svc.cluster.local

  postgresql:
    ## @param postgresql.enabled Deploy PostgreSQL container(s)
    ##
    enabled: false

airflow:
  enabled: true

  postgresql:
    enabled: false

  data:
    # If secret names are provided, use those secrets
    # metadataSecretName: playground-postgresql

    # Otherwise pass connection values in
    metadataConnection:
      user: postgres
      pass: "bWFjb25kbw=="
      protocol: postgresql
      host: playground-postgresql.playground-ns.svc.cluster.local
      port: 5432
      db: airflow
      sslmode: prefer
#
#  fernetKey: "MyKYh7GLUuhYSXbS7Wt9lHUBiKkXDGKWQarS48iGo50="
#  fernetKeySecretName: "playground-fernet-key"
#
#  # Default airflow tag to deploy
#  defaultAirflowTag: "2.3.0"
#
#  # Airflow version (Used to make some decisions based on Airflow Version being deployed)
#  airflowVersion: "2.3.0"
#
#  # Add common labels to all objects and pods defined in this chart.
#  labels: {}

#  # Airflow executor
#  # Options: LocalExecutor, CeleryExecutor, KubernetesExecutor, CeleryKubernetesExecutor
#  executor: "CeleryExecutor"
#
#  # TODO: Ripped from legacy Airflow-Helm 7.x.x
#  # connections:
#  #   - id: my_aws
#  #     type: aws
#  #     extra: |
#  #       {
#  #         "aws_access_key_id": "XXXXXXXX",
#  #         "aws_secret_access_key": "XXXXXXXX",
#  #         "region_name":"eu-central-1"
#  #       }
#  #
#  connections:
#    - id: spark_kubernetes
#      type: spark
#      extra: |
#        {
#          "master": "k8s://foo-bar",
#          "deploy_mode": "cluster"
#        }
#  refreshConnections: true
#
#  # Extra secrets that will be managed by the chart
#  # (You can use them with extraEnv or extraEnvFrom or some of the extraVolumes values).
#  # The format is "key/value" where
#  #    * key (can be templated) is the name of the secret that will be created
#  #    * value: an object with the standard 'data' or 'stringData' key (or both).
#  #          The value associated with those keys must be a string (can be templated)
#  # extraSecrets: { }
#  # eg:
#  # extraSecrets:
#  #   '{{ .Release.Name }}-airflow-connections':
#  #     type: 'Opaque'
#  #     data: |
#  #       AIRFLOW_CONN_GCP: 'base64_encoded_gcp_conn_string'
#  #       AIRFLOW_CONN_AWS: 'base64_encoded_aws_conn_string'
#  #     stringData: |
#  #       AIRFLOW_CONN_OTHER: 'other_conn'
#  #   '{{ .Release.Name }}-other-secret-name-suffix':
#  #     data: |
#  #        ...
#  extraSecrets:
#    '{{ .Release.Name }}-airflow-connections':
#      type: 'Opaque'
#      stringData: |
#        add-connections.sh: |
#          #!/usr/bin/env bash
#          {{- range .Values.connections }}
#          {{- if $.Values.refreshConnections }}
#          airflow connections delete {{ .id | quote | replace `$` `\$` }}
#          {{- end }}
#          airflow connections add {{ .id | quote | replace `$` `\$` }}
#          {{- if .type }} --conn-type {{ .type | quote | replace `$` `\$` }} {{ end -}}
#          {{- if .uri }} --conn-uri {{ .uri | quote | replace `$` `\$` }} {{ end -}}
#          {{- if .host }} --conn-host {{ .host | quote | replace `$` `\$` }} {{ end -}}
#          {{- if .login }} --conn-login {{ .login | quote | replace `$` `\$` }} {{ end -}}
#          {{- if .password }} --conn-password {{ .password | quote | replace `$` `\$` }} {{ end -}}
#          {{- if .schema }} --conn-schema {{ .schema | quote | replace `$` `\$` }} {{ end -}}
#          {{- if .port }} --conn-port {{ .port | quote | replace `$` `\$` }} {{ end -}}
#          {{- if .extra }} --conn-extra {{ ( regexReplaceAll "[\r\n]+" .extra "" ) | quote | replace `$` `\$` }} {{ end -}}
#          {{- end }}
#  customVariables:
#    a: "test-a"
#    b: "test-b"
#  customPools:
#    pool-a:
#      description: "foo"
#      slots: 5
#    pool-b:
#      description: "bar"
#      slots: 10
#
#  # Extra ConfigMaps that will be managed by the chart
#  # (You can use them with extraEnv or extraEnvFrom or some of the extraVolumes values).
#  # The format is "key/value" where
#  #    * key (can be templated) is the name of the configmap that will be created
#  #    * value: an object with the standard 'data' key.
#  #          The value associated with this keys must be a string (can be templated)
#  # extraConfigMaps: { }
#  # eg:
#  # extraConfigMaps:
#  #   '{{ .Release.Name }}-airflow-variables':
#  #     data: |
#  #       AIRFLOW_VAR_HELLO_MESSAGE: "Hi!"
#  #       AIRFLOW_VAR_KUBERNETES_NAMESPACE: "{{ .Release.Namespace }}"
#  extraConfigMaps:
#    '{{ .Release.Name }}-airflow-variables-pools':
#      data: |
#        variables.json: {{ .Values.customVariables | toJson | quote }}
#        pools.json: {{ .Values.customPools | toJson | quote }}
#  # Extra env 'items' that will be added to the definition of airflow containers
#  # a string is expected (can be templated).
#  extraEnv: |
#     - name: AIRFLOW__CORE__LOAD_EXAMPLES
#       value: 'True'
#  workers:
#    replicas: 1
#
#    keda:
#      enabled: false
#
#  scheduler:
#    replicas: 1
#
#    # add checksum for variables and pools
#    podAnnotations:
#      checksum/config-variables-pools: '{{ include (print $.Template.BasePath "/configmaps/extra-configmaps.yaml") . | sha256sum }}'
#      checksum/secrets-connections: '{{ include (print $.Template.BasePath "/secrets/extra-secrets.yaml") . | sha256sum }}'
#
#    # add steps for variables and pools
#    # args: ["bash", "-c", "exec airflow scheduler"]
#    args:
#      - bash
#      - -ec
#      - |
#        echo "Starting..."
#        echo "*** adding Airflow variables..."
#        airflow variables import /opt/airflow/variables-pools/variables.json
#        echo "*** adding Airflow pools..."
#        airflow pools import /opt/airflow/variables-pools/pools.json
#        echo "*** adding Airflow connections..."
#        /opt/airflow/connections/add-connections.sh
#        echo "*** starting scheduler"
#        airflow scheduler
#    extraVolumeMounts:
#      - name: variables-pools
#        mountPath: /opt/airflow/variables-pools/
#      - name: connections
#        mountPath: /opt/airflow/connections/
#
#    extraVolumes:
#      - name: variables-pools
#        configMap:
#          # TODO: why can't this be templated with {{ .Release.Name }}?
#          name: 'orchestrator-airflow-variables-pools'
#          defaultMode: 0755
#      - name: connections
#        secret:
#          # TODO: why can't this be templated with {{ .Release.Name }}?
#          secretName: 'orchestrator-airflow-connections'
#          defaultMode: 0755
#
#  webserver:
#    replicas: 1
#
#  triggerer:
#    enabled: false
#
#  flower:
#    enabled: true
#
#  statsd:
#    enabled: false
#
#  pgbouncer:
#    enabled: false
#
#  redis:
#    enabled: true
#
#  config:
#    webserver:
#      expose_config: 'true'
#
#  dags:
#    persistence:
#      enabled: true
#      accessMode: ReadWriteMany
#      # TODO: why can't this be templated with {{ .Release.Name }}?
#      existingClaim: 'orchestrator-local-dags-pvc'

